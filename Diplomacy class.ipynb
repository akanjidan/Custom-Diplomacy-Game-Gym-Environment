{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5_WTUAPi8Hd"
      },
      "source": [
        "# IMPORT AND NECESSARY INSTALLATIONS AND IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeV5W_Adw6BG",
        "outputId": "bc3d8021-492e-4719-ff46-256e4c9fd86d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting diplomacy\n",
            "  Downloading diplomacy-1.1.2.tar.gz (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bcrypt (from diplomacy)\n",
            "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from diplomacy)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from diplomacy) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from diplomacy) (2023.4)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.10/dist-packages (from diplomacy) (6.3.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from diplomacy) (4.66.4)\n",
            "Collecting ujson (from diplomacy)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->diplomacy)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->diplomacy) (1.16.0)\n",
            "Building wheels for collected packages: diplomacy\n",
            "  Building wheel for diplomacy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diplomacy: filename=diplomacy-1.1.2-py3-none-any.whl size=2339590 sha256=d36c12e5065a8ae20a0c80cfe052efb7c0d3054f6c03ea12891e370bafdb0276\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/27/a5/3da0e6444deaffd4310871e6f20b3c045fa0fc924b84690d5f\n",
            "Successfully built diplomacy\n",
            "Installing collected packages: ujson, humanfriendly, bcrypt, coloredlogs, diplomacy\n",
            "Successfully installed bcrypt-4.1.3 coloredlogs-15.0.1 diplomacy-1.1.2 humanfriendly-10.0 ujson-5.10.0\n",
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.11.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n",
            "Requirement already satisfied: diplomacy in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: bcrypt in /usr/local/lib/python3.10/dist-packages (from diplomacy) (4.1.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from diplomacy) (15.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from diplomacy) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from diplomacy) (2023.4)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.10/dist-packages (from diplomacy) (6.3.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from diplomacy) (4.66.4)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.10/dist-packages (from diplomacy) (5.10.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->diplomacy) (10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->diplomacy) (1.16.0)\n",
            "Collecting stable-baselines3[extra]>=2.0.0a4\n",
            "  Downloading stable_baselines3-2.4.0a1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (2.2.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (4.8.0.76)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (2.5.2)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (2.15.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (4.66.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (13.7.1)\n",
            "Collecting shimmy[atari]~=1.3.0 (from stable-baselines3[extra]>=2.0.0a4)\n",
            "  Downloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (9.4.0)\n",
            "Collecting autorom[accept-rom-license]~=0.6.1 (from stable-baselines3[extra]>=2.0.0a4)\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a4) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a4) (2.31.0)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]>=2.0.0a4) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]>=2.0.0a4) (0.0.4)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.3.0->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a4) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a4) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a4) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a4) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a4) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a4) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a4) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]>=2.0.0a4) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]>=2.0.0a4) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]>=2.0.0a4) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]>=2.0.0a4) (2.16.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[extra]>=2.0.0a4) (6.4.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a4) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a4) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a4) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3[extra]>=2.0.0a4) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.2.2)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446659 sha256=3db45870f4834f9f47cc65ae1fd6c0d5847da8e878e6b4f872d9564a2ec75fcf\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ale-py, shimmy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, AutoROM.accept-rom-license, autorom, nvidia-cusolver-cu12, stable-baselines3\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.6.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 shimmy-1.3.0 stable-baselines3-2.4.0a1\n"
          ]
        }
      ],
      "source": [
        "!pip install diplomacy\n",
        "!pip install gymnasium\n",
        "!pip install diplomacy\n",
        "!pip install \"stable-baselines3[extra]>=2.0.0a4\"\n",
        "\n",
        "import random\n",
        "from diplomacy import Game\n",
        "from diplomacy.utils.export import to_saved_game_format\n",
        "import random\n",
        "from diplomacy import Game\n",
        "from diplomacy.utils.export import to_saved_game_format\n",
        "from stable_baselines3.common.env_checker import check_env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWgb_K3ei2-K"
      },
      "source": [
        "# CUSTOM DIPLOMACY GYM CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOHFOaVhhydG",
        "outputId": "1a0e0ac2-2fce-451c-965f-bab090e77dcf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "import threading\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# import gym\n",
        "from gymnasium import spaces\n",
        "# gym import spaces\n",
        "\n",
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "import signal\n",
        "import atexit\n",
        "import numpy as np\n",
        "\n",
        "import grpc\n",
        "import random\n",
        "from diplomacy import Game\n",
        "from diplomacy.utils.export import to_saved_game_format\n",
        "\n",
        "\n",
        "\n",
        "class DiplomacyStrategyEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    The main OpenAI Gym class. It encapsulates an environment with\n",
        "    arbitrary behind-the-scenes dynamics. An environment can be\n",
        "    partially or fully observed.\n",
        "    The main API methods that users of this class need to know are:\n",
        "        step\n",
        "        reset\n",
        "        render\n",
        "        close\n",
        "        seed\n",
        "    And set the following attributes:\n",
        "        action_space: The Space object corresponding to valid actions\n",
        "        observation_space: The Space object corresponding to valid observations\n",
        "        reward_range: A tuple corresponding to the min and max possible rewards\n",
        "    Note: a default reward range set to [-inf,+inf] already exists. Set it if you want a narrower range.\n",
        "    The methods are accessed publicly as \"step\", \"reset\", etc.. The\n",
        "    non-underscored versions are wrapper methods to which we may add\n",
        "    functionality over time.\n",
        "    \"\"\"\n",
        "    # Set these in ALL subclasses\n",
        "    action_space = None\n",
        "    # observation_space = None\n",
        "\n",
        "    ### CUSTOM ATTRIBUTES\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DiplomacyStrategyEnv, self).__init__()\n",
        "        self.game = None\n",
        "        self.open_game()\n",
        "        # self.game=self.game2\n",
        "        self.current_step = 0\n",
        "        self.reward = 0\n",
        "        # self.observation = None\n",
        "        self._init_observation_space()\n",
        "        self.player = 'FRANCE'\n",
        "        self.max_units = len(self.game.get_state()['units'][self.player])\n",
        "        self.units = self.game.get_state()['units'][self.player]\n",
        "        self.max_locations = len(self.game.map.locs)\n",
        "        self.max_actions = self.check_max_action()  # Adjust this according to the maximum possible actions\n",
        "        # Define action space as a discrete space where each unit can select one action\n",
        "        self.action_space = spaces.MultiDiscrete(self.max_actions)\n",
        "\n",
        "        # self.reset()\n",
        "\n",
        "\n",
        "\n",
        "    def open_game (self):\n",
        "        self.game = Game(map='standard')\n",
        "\n",
        "    def check_max_action(self):\n",
        "        # l = self.game.get_state()['units'][self.player]\n",
        "        possible_orders = self.game.get_all_possible_orders()\n",
        "        add = []\n",
        "        for power_name, power in self.game.powers.items():\n",
        "        # # print(power_name ,\"kdjf\")\n",
        "          if power_name ==self.player:\n",
        "            alllocs = self.game.get_orderable_locations(power_name)\n",
        "            if alllocs !=[]:\n",
        "              for loc in alllocs:\n",
        "                if loc in possible_orders:\n",
        "                  act = possible_orders[loc]\n",
        "                  if act !=[]:\n",
        "                    add.append(len(act))\n",
        "        if add==[]:\n",
        "          add=[]\n",
        "        return add\n",
        "\n",
        "    def observation_data_to_observation(self):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        ### CONSTANTS\n",
        "        NUMBER_OF_OPPONENTS = len(self.game.powers)\n",
        "        NUMBER_OF_PROVINCES = len(self.game.map.locs)\n",
        "        number_of_provinces = NUMBER_OF_PROVINCES\n",
        "\n",
        "        observation = np.zeros(number_of_provinces * 3, dtype=int)\n",
        "\n",
        "        for i, province in enumerate (self.game.map.locs):\n",
        "            # simply for type hint and auto-completion\n",
        "            # id - 1 because the ids begin at 1\n",
        "\n",
        "            observation[i*3] = int(i)\n",
        "\n",
        "            for num, power in enumerate (self.game.map.units):\n",
        "              if province in self.game.get_state()['centers'][power]:\n",
        "                observation[i * 3+1] = int(num)\n",
        "            # the next is to check if that province is a supply center or not\n",
        "              if province in self.game.map.scs:\n",
        "                observation[i * 3 + 2] = 1\n",
        "\n",
        "\n",
        "        reward = 0 #observation_data.previousActionReward\n",
        "        done = self.game.is_game_done #observation_data.done\n",
        "        info = {\"Phase\": self.game.get_current_phase()}\n",
        "        # observations = np.array([2, 5, 9, 8, 0,9, 8,8, 8,0, 9,\n",
        "        #                 0, 8,9, 0,9, 0, 9,9, 0])\n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Run one timestep of the environment's dynamics. When end of\n",
        "        episode is reached, you are responsible for calling `reset()`\n",
        "        to reset this environment's state. action is in form of a list [3,5,2]i.e the choosing index of\n",
        "        the selected action\n",
        "        Accepts an action and returns a tuple (observation, reward, done, info).\n",
        "        Args:\n",
        "            action (object): an action provided by the environment\n",
        "        Returns:\n",
        "            observation (object): agent's observation of the current environment\n",
        "            reward (float) : amount of reward returned after previous action\n",
        "            done (boolean): whether the episode has ended, in which case further step() calls will return undefined results\n",
        "            info (dict): contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)\n",
        "        \"\"\"\n",
        "\n",
        "        # truncated = self.current_step >= self.ep_length\n",
        "        # return self.state, reward, terminated, truncated, {}\n",
        "        prev_state = self.game.get_state()\n",
        "        possible_orders= self.game.get_all_possible_orders()\n",
        "        our_agent = self.player\n",
        "        # unit_actions = np.split(action, self.num_units)\n",
        "        # print(unit_actions)\n",
        "        # Decode each unit's action\n",
        "        actions_taken = []\n",
        "        # self.units\n",
        "\n",
        "        # Process each unit's action\n",
        "        # for unit_action in unit_actions:\n",
        "        #     command_type, target_location = self.decode_action(unit_action)\n",
        "        #     # Apply the action logic for each unit\n",
        "        #     # Example: update the game state based on the action\n",
        "            # (This is where the game-specific logic would go)\n",
        "\n",
        "        for power_name, power in self.game.powers.items():#zip( self.game.map.centers.keys(), self.game.map.units.values()):\n",
        "            # print(power_name, centers)\n",
        "            # possible_orders = self.game.get_all_possible_orders()\n",
        "            chosen_action=[]\n",
        "            if power_name != our_agent:\n",
        "              power_orders = [\n",
        "                  random.choice(possible_orders[loc])\n",
        "                  for loc in self.game.get_orderable_locations(power_name)\n",
        "                  if possible_orders[loc]\n",
        "              ]\n",
        "              # print(power_name, power_orders)\n",
        "              self.game.set_orders(power_name, power_orders)\n",
        "            else:\n",
        "              alllocs=self.game.get_orderable_locations(power_name)\n",
        "              for loc, actions in zip(alllocs,action):\n",
        "                if loc in possible_orders:\n",
        "                  act=possible_orders[loc]\n",
        "                  # print(action,actions,len(act))\n",
        "                  # print('______________',self.action_space)\n",
        "                  if act !=[]:\n",
        "                    if actions >= len(act):\n",
        "                      actions = (len(act)) - 1\n",
        "                    chosen_action.append(act[actions])\n",
        "\n",
        "\n",
        "                  # Set the orders for each power\n",
        "              self.game.set_orders(power_name, chosen_action)\n",
        "\n",
        "        self.game.process()\n",
        "        self.observation, _, _, info = self.observation_data_to_observation()\n",
        "        current_state= self.game.get_state()\n",
        "        # print(self.game.ordered_units)\n",
        "        # print(prev_state)\n",
        "        # print(current_state)\n",
        "        self.calculate_reward(prev_state,actions_taken,current_state,our_agent)\n",
        "        self.current_step += 1\n",
        "        self.max_actions = self.check_max_action()\n",
        "        self.action_space = spaces.MultiDiscrete(self.max_actions)\n",
        "        # terminated = self.game.is_game_done\n",
        "        truncated = False\n",
        "        terminated = self.game.is_game_done\n",
        "\n",
        "        return self.observation, self.reward, terminated, truncated, info\n",
        "\n",
        "    def calculate_reward(self,previous_state, actions_taken, new_state,our_agent):\n",
        "\n",
        "        check_new= new_state['influence'][our_agent]\n",
        "        check_old = previous_state['influence'][our_agent]\n",
        "\n",
        "        diff = list(set(check_new) - set(check_old))\n",
        "        if diff !=[]:\n",
        "          for i in diff:\n",
        "            self.reward += 10 # it captures just a unit\n",
        "            if i in self.game.map.scs:\n",
        "              self.reward +=10 # it captures a supply center\n",
        "\n",
        "        diff = list(set(check_old) - set(check_new))\n",
        "\n",
        "        if diff !=[]:\n",
        "          for i in diff:\n",
        "            self.reward -=10\n",
        "\n",
        "        for action in actions_taken:\n",
        "          if len(action.split())>=3:\n",
        "            if action.split()[2] == '-' and action[-1] in self.game.map.scs:\n",
        "              self.reward +=5\n",
        "            if action.split()[2] == 'S' and action[4] in self.game.map.scs:\n",
        "              self.reward +=5\n",
        "\n",
        "        return self.reward\n",
        "\n",
        "    def reset(self, seed=None):\n",
        "        \"\"\"Resets the state of the environment and returns an initial observation.\n",
        "        Returns: observation (object): the initial observation of the space.\n",
        "        \"\"\"\n",
        "        # super().reset(seed=seed)\n",
        "        # super().reset(seed=seed)\n",
        "        # if seed is not None:\n",
        "        #     np.random.seed(seed)\n",
        "\n",
        "        self.observation, _, _, _ = self.observation_data_to_observation()\n",
        "        self.current_step\n",
        "        self.max_actions = self.check_max_action()\n",
        "        self.action_space = spaces.MultiDiscrete(self.max_actions)\n",
        "        # self.open_game()\n",
        "\n",
        "        return np.array(self.observation),{}\n",
        "\n",
        "\n",
        "    def _init_observation_space(self):\n",
        "        '''\n",
        "        Observation space: [[province_id, owner, is_supply_center, has_unit] * number of provinces]\n",
        "        The last 2 values represent the player id and the province to pick the order.\n",
        "        Eg: If observation_space[2] is [5, 0, 0], then the second province belongs to player 5, is NOT a SC, and does NOT have a unit.\n",
        "        '''\n",
        "        observation_space_description = []\n",
        "        NUMBER_OF_PLAYERS = len(self.game.powers)\n",
        "        NUMBER_OF_PROVINCES =  len(self.game.map.locs)\n",
        "        index_range = 82  # 0 to 81 inclusive\n",
        "        value1_range = 7  # 0 to 6 inclusive\n",
        "        value2_range = 2  # 0 or 1\n",
        "\n",
        "        index_range = 82  # 0 to 81 inclusive\n",
        "        value1_range = 7  # 0 to 6 inclusive\n",
        "        value2_range = 2  # 0 or 1\n",
        "\n",
        "        # Example dataset length\n",
        "        data_length = 82 * 3  # Total number of elements in the dataset\n",
        "\n",
        "        # Create the MultiDiscrete space\n",
        "        self.observation_space = spaces.MultiDiscrete([index_range, value1_range, value2_range] * (data_length // 3))\n",
        "        # print((self.observation_space))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "  gm = DiplomacyStrategyEnv()\n",
        "  # g=gm.reset()\n",
        "  # print((g[0]))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRwKwb5Mivrg"
      },
      "source": [
        "# Testing the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0XAJW7yIis-J"
      },
      "outputs": [],
      "source": [
        "\n",
        "env = DiplomacyStrategyEnv()\n",
        "# If the environment don't follow the interface, an error will be thrown\n",
        "check_env(env, warn=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFWmMA3GjD8G"
      },
      "source": [
        "# VALIDATION\n",
        "\n",
        "\n",
        "If you run the code below, I used our agent as FRANCE in this case, the actions are just random sample from the multidiscreet action space. At the end of the run, you will see the Power that won the game having many units up to or more than 18."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJMlzyeAjjQ7",
        "outputId": "08da8bc6-9eba-4021-e70b-fdd179a6c1d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultiDiscrete([82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2\n",
            " 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2\n",
            " 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2\n",
            " 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2\n",
            " 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2\n",
            " 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2\n",
            " 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2\n",
            " 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2\n",
            " 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2\n",
            " 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2 82  7  2\n",
            " 82  7  2 82  7  2])\n",
            "MultiDiscrete([ 9 10 11])\n",
            "[3 0 8]\n",
            "Step 1\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  0  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 10 done= False\n",
            "Step 2\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 10 done= False\n",
            "Step 3\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 10 done= False\n",
            "Step 4\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 10 done= False\n",
            "Step 5\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 20 done= False\n",
            "Step 6\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 20 done= False\n",
            "Step 7\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  3  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 40 done= False\n",
            "Step 8\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  3  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 40 done= False\n",
            "Step 9\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  3  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 40 done= False\n",
            "Step 10\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  5  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  3  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 40 done= False\n",
            "Step 11\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  5  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  3  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 40 done= False\n",
            "Step 12\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  5  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  3  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 50 done= False\n",
            "Step 13\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  5  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  3  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 50 done= False\n",
            "Step 14\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  5  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  3  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 50 done= False\n",
            "Step 15\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  5  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  3  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 60 done= False\n",
            "Step 16\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  5  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  3  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 80 done= False\n",
            "Step 17\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  5  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  3  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 80 done= False\n",
            "Step 18\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  5  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  3  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 80 done= False\n",
            "Step 19\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  5  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  3  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 80 done= False\n",
            "Step 20\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  5  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  3  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 90 done= False\n",
            "Step 21\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  5  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 90 done= False\n",
            "Step 22\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  5  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 90 done= False\n",
            "Step 23\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  5  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 90 done= False\n",
            "Step 24\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  5  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 100 done= False\n",
            "Step 25\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  5  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 100 done= False\n",
            "Step 26\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  5  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 100 done= False\n",
            "Step 27\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  5  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 100 done= False\n",
            "Step 28\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  5  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 100 done= False\n",
            "Step 29\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  5  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 80 done= False\n",
            "Step 30\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  5  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 80 done= False\n",
            "Step 31\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  5  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 80 done= False\n",
            "Step 32\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 80 done= False\n",
            "Step 33\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 80 done= False\n",
            "Step 34\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 80 done= False\n",
            "Step 35\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  3  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 80 done= False\n",
            "Step 36\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  3  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 80 done= False\n",
            "Step 37\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  3  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 100 done= False\n",
            "Step 38\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  3  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 90 done= False\n",
            "Step 39\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  3  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 90 done= False\n",
            "Step 40\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  3  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 90 done= False\n",
            "Step 41\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 90 done= False\n",
            "Step 42\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 90 done= False\n",
            "Step 43\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 90 done= False\n",
            "Step 44\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 90 done= False\n",
            "Step 45\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 80 done= False\n",
            "Step 46\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 90 done= False\n",
            "Step 47\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 90 done= False\n",
            "Step 48\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 90 done= False\n",
            "Step 49\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 90 done= False\n",
            "Step 50\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  5  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 110 done= False\n",
            "Step 51\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  3  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 110 done= False\n",
            "Step 52\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  3  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 110 done= False\n",
            "Step 53\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  3  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 100 done= False\n",
            "Step 54\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  3  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 120 done= False\n",
            "Step 55\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  3  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 120 done= False\n",
            "Step 56\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  3  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 120 done= False\n",
            "Step 57\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  3  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 120 done= False\n",
            "Step 58\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  3  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 120 done= False\n",
            "Step 59\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  3  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 110 done= False\n",
            "Step 60\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  3  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 110 done= False\n",
            "Step 61\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  3  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 110 done= False\n",
            "Step 62\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  3  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 110 done= False\n",
            "Step 63\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 110 done= False\n",
            "Step 64\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 110 done= False\n",
            "Step 65\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 120 done= False\n",
            "Step 66\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 110 done= False\n",
            "Step 67\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 110 done= False\n",
            "Step 68\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 110 done= False\n",
            "Step 69\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 110 done= False\n",
            "Step 70\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 110 done= False\n",
            "Step 71\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 130 done= False\n",
            "Step 72\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 130 done= False\n",
            "Step 73\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 130 done= False\n",
            "Step 74\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 130 done= False\n",
            "Step 75\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 130 done= False\n",
            "Step 76\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 130 done= False\n",
            "Step 77\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 130 done= False\n",
            "Step 78\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 130 done= False\n",
            "Step 79\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 130 done= False\n",
            "Step 80\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 130 done= False\n",
            "Step 81\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  5  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 130 done= False\n",
            "Step 82\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  5  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 130 done= False\n",
            "Step 83\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  5  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 130 done= False\n",
            "Step 84\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  5  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 130 done= False\n",
            "Step 85\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  5  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 150 done= False\n",
            "Step 86\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  5  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  2  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 130 done= False\n",
            "Step 87\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  5  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  2  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 130 done= False\n",
            "Step 88\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  5  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  2  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 140 done= False\n",
            "Step 89\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  5  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  2  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 140 done= False\n",
            "Step 90\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  5  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  2  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 140 done= False\n",
            "Step 91\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  5  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  2  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 140 done= False\n",
            "Step 92\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  2  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 150 done= False\n",
            "Step 93\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  2  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 150 done= False\n",
            "Step 94\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  2  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 150 done= False\n",
            "Step 95\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  2  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 150 done= False\n",
            "Step 96\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  2  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 150 done= False\n",
            "Step 97\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  2  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 150 done= False\n",
            "Step 98\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  2  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 150 done= False\n",
            "Step 99\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  2  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 160 done= False\n",
            "Step 100\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 160 done= False\n",
            "Step 101\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 160 done= False\n",
            "Step 102\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  5  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 160 done= False\n",
            "Step 103\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 180 done= False\n",
            "Step 104\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 180 done= False\n",
            "Step 105\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 190 done= False\n",
            "Step 106\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  2  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 190 done= False\n",
            "Step 107\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 200 done= False\n",
            "Step 108\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 200 done= False\n",
            "Step 109\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 200 done= False\n",
            "Step 110\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 190 done= False\n",
            "Step 111\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 190 done= False\n",
            "Step 112\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 190 done= False\n",
            "Step 113\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 180 done= False\n",
            "Step 114\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 180 done= False\n",
            "Step 115\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  2  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 190 done= False\n",
            "Step 116\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  2  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 200 done= False\n",
            "Step 117\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  2  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 200 done= False\n",
            "Step 118\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  2  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 200 done= False\n",
            "Step 119\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  2  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 210 done= False\n",
            "Step 120\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  2  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 210 done= False\n",
            "Step 121\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  2  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  3  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 210 done= False\n",
            "Step 122\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  2  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 210 done= False\n",
            "Step 123\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  2  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 210 done= False\n",
            "Step 124\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  3  1  9  2  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 220 done= False\n",
            "Step 125\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 126\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 127\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  1  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 128\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 129\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 130\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 131\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  0  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 132\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  0  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 133\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  0  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 134\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  0  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 135\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  0  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 210 done= False\n",
            "Step 136\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 137\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 138\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 139\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 140\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 141\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 142\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 143\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 144\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 250 done= False\n",
            "Step 145\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 250 done= False\n",
            "Step 146\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 147\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  0  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  2  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 148\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  0  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  2  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 149\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  0  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  2  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 150\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  0  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  2  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 151\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  0  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  2  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 152\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  2  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  0  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  2  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 153\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  0  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  2  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 154\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  0  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  2  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 155\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  0  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  2  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 156\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  0  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  2  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 157\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  0  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  2  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 158\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  0  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  2  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 159\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 160\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 161\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 162\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 163\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 164\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 165\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 166\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 167\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 168\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  6  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 250 done= False\n",
            "Step 169\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  6  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 250 done= False\n",
            "Step 170\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  6  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 250 done= False\n",
            "Step 171\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  6  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 172\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  6  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  4  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 173\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 174\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 175\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 176\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 177\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 178\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 179\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 280 done= False\n",
            "Step 180\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 280 done= False\n",
            "Step 181\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 280 done= False\n",
            "Step 182\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 290 done= False\n",
            "Step 183\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 290 done= False\n",
            "Step 184\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 300 done= False\n",
            "Step 185\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 300 done= False\n",
            "Step 186\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 300 done= False\n",
            "Step 187\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  2  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 300 done= False\n",
            "Step 188\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  6  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 290 done= False\n",
            "Step 189\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  6  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 290 done= False\n",
            "Step 190\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  6  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 280 done= False\n",
            "Step 191\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  6  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 280 done= False\n",
            "Step 192\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            " 56  6  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  6  1 77  0  0 78  2  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 193\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  6  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 250 done= False\n",
            "Step 194\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  6  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 250 done= False\n",
            "Step 195\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  6  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 250 done= False\n",
            "Step 196\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 250 done= False\n",
            "Step 197\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 250 done= False\n",
            "Step 198\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 250 done= False\n",
            "Step 199\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 200\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 201\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 202\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 203\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 220 done= False\n",
            "Step 204\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 220 done= False\n",
            "Step 205\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 206\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 207\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 208\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  6  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 209\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 210\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 211\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 212\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 250 done= False\n",
            "Step 213\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 250 done= False\n",
            "Step 214\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 215\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 216\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 217\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 218\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 219\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 220\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  2  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 221\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 222\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 223\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 220 done= False\n",
            "Step 224\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 220 done= False\n",
            "Step 225\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 220 done= False\n",
            "Step 226\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 220 done= False\n",
            "Step 227\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 220 done= False\n",
            "Step 228\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 229\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 220 done= False\n",
            "Step 230\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 220 done= False\n",
            "Step 231\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  4  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 210 done= False\n",
            "Step 232\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 210 done= False\n",
            "Step 233\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 210 done= False\n",
            "Step 234\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 200 done= False\n",
            "Step 235\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  0  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 200 done= False\n",
            "Step 236\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 190 done= False\n",
            "Step 237\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 190 done= False\n",
            "Step 238\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 190 done= False\n",
            "Step 239\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 210 done= False\n",
            "Step 240\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 210 done= False\n",
            "Step 241\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 210 done= False\n",
            "Step 242\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 210 done= False\n",
            "Step 243\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  0  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  6  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 210 done= False\n",
            "Step 244\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  6  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 200 done= False\n",
            "Step 245\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  6  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 200 done= False\n",
            "Step 246\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  6  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 210 done= False\n",
            "Step 247\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  6  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 248\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  6  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 249\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  6  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 250\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  6  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 251\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  6  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 252\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  6  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 253\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  6  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 254\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  6  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 255\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  6  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 256\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  1  1 31  0  0\n",
            " 32  0  0 33  6  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  6  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 220 done= False\n",
            "Step 257\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 220 done= False\n",
            "Step 258\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 220 done= False\n",
            "Step 259\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  1  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  0  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 260\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 261\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 262\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 263\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 230 done= False\n",
            "Step 264\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  2  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  1  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 250 done= False\n",
            "Step 265\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 266\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  6  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 267\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  6  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 268\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  6  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 269\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  6  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 270\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  6  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 271\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  6  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 272\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  0  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  6  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 273\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  6  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  6  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 274\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  6  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  6  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 275\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  6  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  1  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  2  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  6  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  0  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 276\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  6  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 277\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  6  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 240 done= False\n",
            "Step 278\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  6  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  1  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  5  1 46  0  0 47  0  0\n",
            " 48  4  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 279\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  6  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  5  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 280\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  6  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  5  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 281\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  6  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  5  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 282\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  5  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  5  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 283\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  5  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  5  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 284\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  2  1  9  5  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  5  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 270 done= False\n",
            "Step 285\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  0  1  9  5  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  5  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 286\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  0  1  9  5  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  5  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 287\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  0  1  9  5  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  5  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 288\n",
            "envifonsmnd obs === False\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  0  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  0  1  9  5  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  5  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 289\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  0  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  0  1  9  5  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  5  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 260 done= False\n",
            "Step 290\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  0  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  0  1  9  5  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  5  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 250 done= False\n",
            "Step 291\n",
            "envifonsmnd obs === True\n",
            "obs= [ 0  0  0  1  0  0  2  0  0  3  0  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "  8  0  1  9  5  1 10  0  0 11  0  0 12  0  0 13  4  1 14  0  1 15  0  0\n",
            " 16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  5  1 22  0  0 23  1  1\n",
            " 24  0  0 25  0  0 26  0  0 27  0  0 28  4  1 29  0  0 30  6  1 31  0  0\n",
            " 32  0  0 33  5  1 34  1  1 35  0  0 36  2  1 37  0  0 38  0  0 39  0  1\n",
            " 40  6  1 41  0  1 42  0  0 43  0  0 44  4  1 45  1  1 46  0  0 47  0  0\n",
            " 48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            " 56  0  1 57  0  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            " 64  0  0 65  0  0 66  0  0 67  5  1 68  0  0 69  0  1 70  4  1 71  0  0\n",
            " 72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  6  1 79  0  0\n",
            " 80  0  0 81  0  0] reward= 250 done= True\n",
            "Goal reached! reward= 250\n"
          ]
        }
      ],
      "source": [
        "env = DiplomacyStrategyEnv()\n",
        "\n",
        "obs, _ = env.reset()\n",
        "# env.render()\n",
        "\n",
        "print(env.observation_space)\n",
        "print(env.action_space)\n",
        "print(env.action_space.sample())\n",
        "\n",
        "GO_LEFT = list(np.random.randint(10, size=3))\n",
        "# Hardcoded best agent: always go left!\n",
        "n_steps = 20000\n",
        "on=[0]\n",
        "for step in range(n_steps):\n",
        "# while not done:\n",
        "    print(f\"Step {step + 1}\")\n",
        "    act = env.action_space\n",
        "    # print(act)\n",
        "    GO_LEFT=[]\n",
        "    if act !=[]:\n",
        "      for y in act:\n",
        "        y=int(y.sample())\n",
        "        # print(y,act,'-------------------')\n",
        "        GO_LEFT.append(y)\n",
        "      Go_LEFT = list(GO_LEFT)\n",
        "\n",
        "    # Hardcoded best agent: always go left!\n",
        "    obs, reward, terminated, truncated, info = env.step(GO_LEFT)\n",
        "    print(\"envifonsmnd obs ===\",(on==obs).all())\n",
        "    on=obs\n",
        "    done = terminated\n",
        "    print(\"obs=\", obs, \"reward=\", reward, \"done=\", done)\n",
        "    # env.render()\n",
        "    if done:\n",
        "        print(\"Goal reached!\", \"reward=\", reward)\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXnGrVdcjxnY"
      },
      "source": [
        "# Training with PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHy7KOC0uSIK",
        "outputId": "195018ce-48dd-4f12-8521-f795fc432c29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TeUXNRiVsqs6g81xae7HT4XQmkrP7Km5\n",
            "To: /content/ppo_diplomacy.zip\n",
            "\r  0% 0.00/11.6M [00:00<?, ?B/s]\r100% 11.6M/11.6M [00:00<00:00, 164MB/s]\n"
          ]
        }
      ],
      "source": [
        "# !gdown 1TeUXNRiVsqs6g81xae7HT4XQmkrP7Km5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PnvzLAij_hq",
        "outputId": "7e9a36d1-9fa4-4e71-9d47-655dc1eee100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  0  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [0.] done= [False]\n",
            "Step 2\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  0  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [0.] done= [False]\n",
            "Step 3\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  0  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [0.] done= [False]\n",
            "Step 4\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  0  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [20.] done= [False]\n",
            "Step 5\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  0  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [20.] done= [False]\n",
            "Step 6\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  0  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  0  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [20.] done= [False]\n",
            "Step 7\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  0  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [20.] done= [False]\n",
            "Step 8\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  0  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [20.] done= [False]\n",
            "Step 9\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  0  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  3  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  0  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [20.] done= [False]\n",
            "Step 10\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  0  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [30.] done= [False]\n",
            "Step 11\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  0  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [30.] done= [False]\n",
            "Step 12\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  0  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  0  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [50.] done= [False]\n",
            "Step 13\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [50.] done= [False]\n",
            "Step 14\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [50.] done= [False]\n",
            "Step 15\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  5  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [50.] done= [False]\n",
            "Step 16\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  3  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [50.] done= [False]\n",
            "Step 17\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  3  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [50.] done= [False]\n",
            "Step 18\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  5  1 41  0  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  0  1 77  0  0 78  3  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [50.] done= [False]\n",
            "Step 19\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  3  1 41  0  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  5  1 77  0  0 78  3  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [40.] done= [False]\n",
            "Step 20\n",
            "Action:  [[1 2 9]]\n",
            "obs= [[ 0  0  0  1  0  0  2  0  0  3  6  1  4  0  0  5  0  0  6  0  0  7  0  0\n",
            "   8  2  1  9  3  1 10  0  0 11  0  0 12  0  0 13  2  1 14  0  1 15  0  0\n",
            "  16  0  0 17  0  0 18  0  0 19  0  0 20  6  1 21  3  1 22  0  0 23  1  1\n",
            "  24  0  0 25  0  0 26  0  0 27  0  0 28  0  1 29  0  0 30  3  1 31  0  0\n",
            "  32  0  0 33  3  1 34  1  1 35  0  0 36  1  1 37  0  0 38  0  0 39  2  1\n",
            "  40  3  1 41  0  1 42  0  0 43  0  0 44  4  1 45  0  1 46  0  0 47  0  0\n",
            "  48  2  1 49  0  0 50  0  0 51  0  1 52  0  0 53  4  1 54  0  0 55  6  1\n",
            "  56  0  1 57  5  1 58  0  0 59  0  0 60  6  1 61  0  0 62  0  0 63  0  0\n",
            "  64  0  0 65  0  0 66  0  0 67  0  1 68  0  0 69  0  1 70  0  1 71  0  0\n",
            "  72  0  0 73  0  0 74  0  0 75  4  1 76  5  1 77  0  0 78  3  1 79  0  0\n",
            "  80  0  0 81  0  0]] reward= [40.] done= [False]\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "# Parallel environments\n",
        "vec_env = make_vec_env(DiplomacyStrategyEnv, n_envs=1)\n",
        "\n",
        "model = PPO(\"MlpPolicy\", vec_env, verbose=1,tensorboard_log='PPO' )\n",
        "model.learn(total_timesteps=25000,log_interval=1, tb_log_name='PPO',progress_bar = True)\n",
        "model.save(\"ppo_diplomacy\")\n",
        "\n",
        "del model # remove to demonstrate saving and loading\n",
        "\n",
        "model = PPO.load(\"ppo_diplomacy\")\n",
        "\n",
        "obs = vec_env.reset()\n",
        "obs = vec_env.reset()\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    print(f\"Step {step + 1}\")\n",
        "    print(\"Action: \", action)\n",
        "    obs, reward, done, info = vec_env.step(action)\n",
        "    print(\"obs=\", obs, \"reward=\", reward, \"done=\", done)\n",
        "    # vec_env.render()\n",
        "    if done:\n",
        "        # Note that the VecEnv resets automatically\n",
        "        # when a done signal is encountered\n",
        "        print(\"Goal reached!\", \"reward=\", reward)\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
